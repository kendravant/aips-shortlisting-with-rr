{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic models on ynp feature set for Role Requirements\n",
    "\n",
    "* Build the ynp 1-hot feature set from the Presto extraction\n",
    "* Try logistic regression, tree, random classifier, xgboost\n",
    "* SVM takes too long on this size of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are there so many applications in the cutdown set with only one feature?\n",
    "\n",
    "It seems believable that we can't learn much about THE SUBSET OF PEOPLE WHO ARE ACTUALLY SHORTLISTED AND REJECTED from the Role Requirements data. For the questions that are really important, it's likely that the applications will simply be ignored and left in inbox.\n",
    "\n",
    "One way to check this would be to look at the distributions of answers to key questions (like right to work) in the general population of applicants vs the applicants with shortlisted / rejected signals.\n",
    "\n",
    "Consider adding the job sub-class (discipline) as an additional feature. This shouldn't much help the linear models like logistic regression (at least without adding cross terms) but might well be very helpful to tree models and non-linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "import time\n",
    "import xgboost as xgb\n",
    "\n",
    "from sqlalchemy.engine import create_engine\n",
    "import prestodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn=prestodb.dbapi.connect(\n",
    "    host='searchquality-presto.dataservices.prod.outfra.xyz',\n",
    "    port=8889,\n",
    "    user='user',\n",
    "    catalog='hive',\n",
    "    schema='sandbox',\n",
    ")\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT top 100 FROM sandbox.kendra_nac_jobs')\n",
    "rows = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to presto if we want to pick up the data directly\n",
    "engine = create_engine('presto://searchquality-presto.dataservices.prod.outfra.xyz:8889/hive/default')\n",
    "conn=engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from a local file extracted from Presto\n",
    "# Sort by application ID in order to construct the sparse matrix correctly later\n",
    "df = pd.read_csv('/home/ubuntu/data/rr/ynp_training_data.csv')\n",
    "df.sort_values(by=['application_id'], inplace = True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the sparse matrix requires us to know how many features are present in each case\n",
    "# We also need the rolled up case by case outcome\n",
    "r = df.groupby(['application_id','outcome'], as_index = False)['feature_id'].count()\n",
    "print('There are ', len(r), ' cases in total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['feature_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_multifeatures = r[(r.feature_id > 2) & (r.feature_id < 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_multifeatures['feature_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balance of the set\n",
    "r_multifeatures.outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the baseline accuracy from predicting all 'Rejected'\n",
    "(len(r_multifeatures[r_multifeatures.outcome == 'Rejected']))/(len(r_multifeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multifeatures = df.merge(r_multifeatures[['application_id']], \n",
    "                            left_on='application_id', \n",
    "                            right_on='application_id', \n",
    "                            how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the sparse matrix from all cases\n",
    "data    = np.ones((len(df_multifeatures),), dtype=int)\n",
    "indptr  = np.concatenate([np.array([0]), np.cumsum(np.array(r_multifeatures.feature_id))])  # first element is zero, subsequent elements are indptr[i-1] + num_features in row\n",
    "indices = np.array(df_multifeatures.feature_id-200000)\n",
    "\n",
    "N = csr_matrix((data, indices, indptr))\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(N, r_multifeatures.outcome, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "# Did not complete - likely to be extremely slow on a dataset of this size\n",
    "svm_mo = svm.SVC()\n",
    "svm_mo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_mo = RandomForestClassifier(n_estimators=10)\n",
    "rf_mo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "t0 = time.time()\n",
    "\n",
    "tree_mo = tree.DecisionTreeClassifier()\n",
    "tree_mo.fit(X_train,y_train)\n",
    "\n",
    "print('Time to train ', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "t0 = time.time()\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print('Time to train ', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(scores, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "\n",
    "train_binary_labels = (y_train == 'Shortlisted').astype('int')\n",
    "test_binary_labels = (y_test == 'Shortlisted').astype('int')\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label = train_binary_labels)\n",
    "dtest = xgb.DMatrix(X_test, label = test_binary_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 10, 'eta': 0.1, 'silent': 1, 'objective': 'binary:logistic', 'eval':'auc'}\n",
    "evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "num_round = 2000\n",
    "bst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=50, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = bst.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance['f6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_xgb = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(test_binary_labels > 0.5, scores_xgb > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(45341+904268)/len(scores_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
